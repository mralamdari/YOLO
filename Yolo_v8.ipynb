{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mralamdari/YOLO/blob/main/Yolo_v8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xVXK-JCZtAQZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fz4D4hFnsI04"
      },
      "outputs": [],
      "source": [
        "#install necessary libraries\n",
        "!pip install awscli\n",
        "!pip install ultralytics\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data"
      ],
      "metadata": {
        "id": "CV31ERFmWIWf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IP4ViZFoHDr",
        "outputId": "ffa35e9d-b3f8-411f-ce34-b83fcc618bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OIDv4_ToolKit'...\n",
            "remote: Enumerating objects: 499, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 499 (delta 32), reused 52 (delta 31), pack-reused 444\u001b[K\n",
            "Receiving objects: 100% (499/499), 34.11 MiB | 18.74 MiB/s, done.\n",
            "Resolving deltas: 100% (189/189), done.\n"
          ]
        }
      ],
      "source": [
        "#clone OIDv4_ToolKit\n",
        "!git clone https://github.com/mralamdari/OIDv4_ToolKit.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1GTFM1JsmPL",
        "outputId": "02c542fe-49f5-4cb3-aa61-7c96dc67ea9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OIDv4_ToolKit\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Truck.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...145%, 0 MB, 34788 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 1138 MB, 29428 KB/s, 39 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mTruck\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 8078 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 50 images.\u001b[0m\n",
            "    [INFO] | Download of 50 images in train.\u001b[0m\n",
            "100% 50/50 [00:50<00:00,  1.00s/it]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Truck of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Person.\u001b[0m\n",
            "\n",
            "\u001b[95mPerson\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 248384 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 50 images.\u001b[0m\n",
            "    [INFO] | Download of 50 images in train.\u001b[0m\n",
            "100% 50/50 [00:55<00:00,  1.12s/it]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Person of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "    [INFO] | Downloading Tree.\u001b[0m\n",
            "\n",
            "\u001b[95mTree\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 289999 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 50 images.\u001b[0m\n",
            "    [INFO] | Download of 50 images in train.\u001b[0m\n",
            "100% 50/50 [00:54<00:00,  1.09s/it]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Tree of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%cd OIDv4_ToolKit\n",
        "\n",
        "#Write your desired objects (--classes) and data type (--type_csv)  and the number of images you want (--limit)\n",
        "# !python3 main.py downloader --classes Truck --type_csv train --limit 100\n",
        "\n",
        "!python3 main.py downloader --classes Truck Person Tree --type_csv train --limit 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVX3Hk6ZALcj",
        "outputId": "dd4725f2-d512-4c69-8e3c-b7381dd2b350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently in subdirectory: train\n",
            "Converting annotations for class: Tree\n",
            "100% 50/50 [00:05<00:00,  9.93it/s]\n",
            "Converting annotations for class: Person\n",
            "100% 50/50 [00:02<00:00, 22.52it/s]\n",
            "Converting annotations for class: Truck\n",
            "100% 50/50 [00:01<00:00, 45.39it/s]\n"
          ]
        }
      ],
      "source": [
        "!python mralamdari_annotations_converter.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/data/obj/train/Truck/'\n",
        "os.makedirs('/content/train/images', exist_ok=True)\n",
        "os.makedirs('/content/train/labels', exist_ok=True)\n",
        "# os.rename('/content/data', '/content/old_data')\n",
        "# os.rename('/content/train', '/content/data')\n",
        "\n",
        "\n",
        "for i in os.listdir(path):\n",
        "  file_type = 'labels' if i[-4:] == '.txt' else 'images'\n",
        "  os.rename(path+i, f'/content/train/{file_type}/{i}')"
      ],
      "metadata": {
        "id": "MQ5SNIxG2j-2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.rename('/content/data', '/content/old_data')\n",
        "os.rename('/content/train', '/content/data')"
      ],
      "metadata": {
        "id": "a8zUYKVfEmzR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install ultralytics\n",
        "from ultralytics import YOLO\n",
        "model = YOLO('yolov8n.yaml')"
      ],
      "metadata": {
        "id": "vLz9qNbRErBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_ROOT = '/content/data/'\n",
        "\n",
        "with open('/content/config.yaml', 'w+') as f:\n",
        "    config_files = f.write(f\"\"\"path: '{DATA_ROOT}' # dataset root dir\n",
        "train: images  # train images (relative to 'path')\n",
        "val: val_images  # val images (relative to 'path')\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: Truck\"\"\")\n",
        "\n",
        "\n",
        "results = model.train(data='/content/config.yaml', epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "RW7B9Jgb6H2Y",
        "outputId": "57f610e5-92de-4b9e-eb59-ca2af46088f9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.149 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/config.yaml, epochs=1, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=0, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.0, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train9\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yml'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'detect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'segment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'yaml_file'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\nNote dataset download directory is '{DATASETS_DIR}'. You can update this in '{SETTINGS_YAML}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \nDataset '/content/config.yaml' images not found ‚ö†Ô∏è, missing path '/content/data/val_images'\nNote dataset download directory is '/content/OIDv4_ToolKit/datasets'. You can update this in '/root/.config/Ultralytics/settings.yaml'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-0435b23022f1>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/config.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'trainer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resume'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'yaml_file'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error ‚ùå {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Dataset '/content/config.yaml' error ‚ùå \nDataset '/content/config.yaml' images not found ‚ö†Ô∏è, missing path '/content/data/val_images'\nNote dataset download directory is '/content/OIDv4_ToolKit/datasets'. You can update this in '/root/.config/Ultralytics/settings.yaml'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Detection"
      ],
      "metadata": {
        "id": "PRhn_kDuWeIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# path = '/content/data/obj/train/'\n",
        "# os.makedirs('/content/train/images', exist_ok=True)\n",
        "# os.makedirs('/content/train/labels', exist_ok=True)\n",
        "\n",
        "# for j in os.listdir('/content/data/obj/train/'):\n",
        "#   for i in os.listdir(path+j):\n",
        "#     file_type = 'labels' if i[-4:] == '.txt' else 'images'\n",
        "#     os.rename(path+j+'/'+i, f'/content/train/{file_type}/{i}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/config.yaml', 'w+') as f:\n",
        "    config_files = f.write(f\"\"\"path: /content/train # dataset root dir\n",
        "train: images  # train images (relative to 'path')\n",
        "val: images  # val images (relative to 'path')\n",
        "\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: Truck\n",
        "  1: Person\n",
        "  2: Tree\"\"\")\n",
        "\n",
        "results = model.train(data='/content/config.yaml', epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LliI1oaPRiTZ",
        "outputId": "f6b4dec3-3db1-422d-9623-23eefc6833fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.149 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/config.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:00<00:00, 13.9MB/s]\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011433 parameters, 3011417 gradients\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels... 149 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 149/149 [00:00<00:00, 712.07it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/train/labels.cache... 149 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 149/149 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# os.makedirs('/content/data/obj/train/Labels/', exist_ok=True)\n",
        "# for i in os.listdir('/content/data/obj/train/Truck/'):\n",
        "#   if i[-4:] == '.txt':\n",
        "#     os.rename(f'/content/data/obj/train/Truck/{i}', f'/content/data/obj/train/Labels/{i}')"
      ],
      "metadata": {
        "id": "zr0yad9hl_DB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# os.makedirs(f'/content/data/images/train/', exist_ok=True)\n",
        "# os.makedirs(f'/content/data/labels/train/', exist_ok=True)\n",
        "# os.makedirs(f'/content/data/images/test/', exist_ok=True)\n",
        "# os.makedirs(f'/content/data/labels/test/', exist_ok=True)\n",
        "\n",
        "# path = '/content/data/obj/train/'\n",
        "# DATA_ROOT = '/content/data/'\n",
        "\n",
        "# VAL_THRESHOLD = 0.2\n",
        "\n",
        "# for category in os.listdir(path):\n",
        "#   category_path = path+category\n",
        "\n",
        "#   for i in os.listdir(category_path):\n",
        "#     if i[-4:] == '.txt':\n",
        "#       file_name = i[:-4]\n",
        "#       image_file = category_path + '/' + file_name + '.jpg'\n",
        "#       label_file = category_path + '/' + file_name + '.txt'\n",
        "#       rand_num = np.random.rand()\n",
        "#       target = 'test' if rand_num <= VAL_THRESHOLD else 'train'\n",
        "#       os.rename(image_file, f'/content/data/images/{target}/{file_name}.img')\n",
        "#       os.rename(label_file, f'/content/data/labels/{target}/{file_name}.tx')"
      ],
      "metadata": {
        "id": "F_zZQBhvm4Lv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fYKroTzvALzs"
      },
      "outputs": [],
      "source": [
        "os.makedirs(f'/content/data/train/images/', exist_ok=True)\n",
        "os.makedirs(f'/content/data/train/labels/', exist_ok=True)\n",
        "os.makedirs(f'/content/data/test/images/', exist_ok=True)\n",
        "os.makedirs(f'/content/data/test/labels/', exist_ok=True)\n",
        "\n",
        "\n",
        "path = '/content/data/obj/train/'\n",
        "DATA_ROOT = '/content/data/'\n",
        "\n",
        "VAL_THRESHOLD = 0.2\n",
        "\n",
        "for category in os.listdir(path):\n",
        "  category_path = path+category\n",
        "\n",
        "  for i in os.listdir(category_path):\n",
        "    if i[-4:] == '.txt':\n",
        "      file_name = i[:-4]\n",
        "      image_file = category_path + '/' + file_name + '.jpg'\n",
        "      label_file = category_path + '/' + file_name + '.txt'\n",
        "      rand_num = np.random.rand()\n",
        "      target = 'test' if rand_num <= VAL_THRESHOLD else 'train'\n",
        "      os.rename(image_file, f'/content/data/{target}/images/{file_name}.img')\n",
        "      os.rename(label_file, f'/content/data/{target}/labels/{file_name}.tx')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.rename('/content/data/obj', '/content/obj')\n",
        "os.rename('/content/data/obj.names', '/content/obj.names')\n",
        "os.rename('/content/data/train.txt', '/content/train.txt')"
      ],
      "metadata": {
        "id": "75_rxGXmjt_s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys8lt5EHlIRS",
        "outputId": "28484e76-559f-4652-d47f-14b96861f217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.23M/6.23M [00:00<00:00, 49.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# model = YOLO('yolov8n.yaml')\n",
        "model = YOLO('yolov8n.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/config.yaml', 'w+') as f:\n",
        "#     config_files = f.write(f\"\"\"path: /content/data/images/ # dataset root dir\n",
        "# train: train  # train images (relative to 'path')\n",
        "# val: test  # val images (relative to 'path')\n",
        "\n",
        "# # Classes\n",
        "# names:\n",
        "#   0: Truck\"\"\")"
      ],
      "metadata": {
        "id": "ndtl7VR3nxo0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "A7uGNl9QnHjX"
      },
      "outputs": [],
      "source": [
        "with open('/content/config.yaml', 'w+') as f:\n",
        "    config_files = f.write(f\"\"\"path: /content/train # dataset root dir\n",
        "train: images  # train images (relative to 'path')\n",
        "val: images  # val images (relative to 'path')\n",
        "\n",
        "\n",
        "                           # Classes\n",
        "names:\n",
        "  0: Truck\n",
        "  1: Person\n",
        "  2: Tree\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xZwrF8vklfUd",
        "outputId": "7a9f7800-2950-48a5-88b9-93138d4279ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.149 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (AMD EPYC 7B12)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/config.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011433 parameters, 3011417 gradients\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train3', view at http://localhost:6006/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36mget_img_files\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{self.prefix}No images found'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: \u001b[34m\u001b[1mtrain: \u001b[0mNo images found",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cc73658c24a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/config.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m  \u001b[0;31m# attach optional HUB session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;31m# Update model and cfg after training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mddp_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_ddp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m_setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mRANK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mget_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# init dataset *.cache only once if DDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36mbuild_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \"\"\"\n\u001b[1;32m     28\u001b[0m         \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/build.py\u001b[0m in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_yolo_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;34m\"\"\"Build YOLO Dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     return YOLODataset(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgsz\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, use_segments, use_keypoints, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_segments\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_keypoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Can not use both segments and keypoints.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./labels.cache'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfraction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_img_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# single_cls and include_class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/base.py\u001b[0m in \u001b[0;36mget_img_files\u001b[0;34m(self, img_path)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{self.prefix}No images found'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.prefix}Error loading data from {img_path}\\n{HELP_URL}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mim_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_files\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: \u001b[34m\u001b[1mtrain: \u001b[0mError loading data from /content/train/images\nSee https://docs.ultralytics.com/yolov5/tutorials/train_custom_data"
          ]
        }
      ],
      "source": [
        "results = model.train(data='/content/config.yaml', epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXNW8w1yom2L"
      },
      "outputs": [],
      "source": [
        "!scp -r runs '/content/drive/MyDrive/Computer Vision Projects/Yolo/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6yLKQuY36pO",
        "outputId": "ddd35253-2575-4a42-e3b2-1931dc43b789"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.147 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3005843 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data/labels.cache... 100 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:37<00:00,  5.35s/it]\n",
            "                   all        100        161      0.576       0.36       0.43      0.237\n",
            "Speed: 1.6ms preprocess, 284.0ms inference, 0.0ms loss, 2.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "metrics = model.val()  # evaluate model performance on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJbrQuNg36ye"
      },
      "outputs": [],
      "source": [
        "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
        "path = model.export(format=\"onnx\")  # export the model to ONNX format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVBG6TVO3keb"
      },
      "outputs": [],
      "source": [
        "!scp -r runs '/content/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre trained"
      ],
      "metadata": {
        "id": "BvC-ffzJI7ro"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vavmhWN7n9fH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55bf51d0-db2d-4b33-aaee-6633c05a06ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.148 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/content/drive/MyDrive/Computer Vision Projects/Yolo/runs/detect/train5/weights/best.pt, data=coco128.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
            "\n",
            "Dataset 'coco128.yaml' images not found ‚ö†Ô∏è, missing path '/content/OIDv4_ToolKit/datasets/coco128/images/train2017'\n",
            "Downloading https://ultralytics.com/assets/coco128.zip to '/content/OIDv4_ToolKit/datasets/coco128.zip'...\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.66M/6.66M [00:00<00:00, 74.8MB/s]\n",
            "Unzipping /content/OIDv4_ToolKit/datasets/coco128.zip to /content/OIDv4_ToolKit/datasets...\n",
            "Dataset download success ‚úÖ (1.1s), saved to \u001b[1m/content/OIDv4_ToolKit/datasets\u001b[0m\n",
            "\n",
            "Overriding model.yaml nc=1 with nc=80\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/OIDv4_ToolKit/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<00:00, 1472.57it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/OIDv4_ToolKit/datasets/coco128/labels/train2017.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/OIDv4_ToolKit/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/3         0G      2.879      5.692      3.237        294        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:15<00:00, 16.96s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:38<00:00,  9.65s/it]\n",
            "                   all        128        929          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/3         0G      2.921      5.711      3.259        251        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:03<00:00, 15.40s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:38<00:00,  9.62s/it]\n",
            "                   all        128        929          0          0          0          0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/3         0G      2.851      5.679      3.272        158        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:02<00:00, 15.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:45<00:00, 11.44s/it]\n",
            "                   all        128        929          0          0          0          0\n",
            "\n",
            "3 epochs completed in 0.142 hours.\n",
            "Optimizer stripped from runs/detect/train/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from runs/detect/train/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating runs/detect/train/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.148 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:37<00:00,  9.50s/it]\n",
            "                   all        128        929          0          0          0          0\n",
            "Speed: 7.1ms preprocess, 266.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train\u001b[0m\n",
            "Ultralytics YOLOv8.0.148 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/OIDv4_ToolKit/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:32<00:00,  4.10s/it]\n",
            "                   all        128        929          0          0          0          0\n",
            "Speed: 2.3ms preprocess, 240.5ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Load a model\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"/content/drive/MyDrive/Computer Vision Projects/Yolo/runs/detect/train5/weights/best.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
        "metrics = model.val()  # evaluate model performance on the validation set"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
        "path = model.export(format=\"onnx\")  # export the model to ONNX format"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td6o_WG1k7Ew",
        "outputId": "b7d4e9c0-f051-40a2-d660-dee75be3cc62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
            "image 1/1 /content/OIDv4_ToolKit/bus.jpg: 640x480 (no detections), 333.9ms\n",
            "Speed: 5.7ms preprocess, 333.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Ultralytics YOLOv8.0.148 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.14.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 2.6s, saved as 'runs/detect/train/weights/best.onnx' (12.2 MB)\n",
            "\n",
            "Export complete (4.7s)\n",
            "Results saved to \u001b[1m/content/OIDv4_ToolKit/runs/detect/train/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train/weights/best.onnx imgsz=640 \n",
            "Validate:        yolo val task=detect model=runs/detect/train/weights/best.onnx imgsz=640 data=None \n",
            "Visualize:       https://netron.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
        "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
        "metrics = model.val()  # evaluate model performance on the validation set\n",
        "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
        "path = model.export(format=\"onnx\")  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "HEIG3ZvtJniC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classification"
      ],
      "metadata": {
        "id": "DOVFVvV8WhFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjust dataset for the Classification task only"
      ],
      "metadata": {
        "id": "0VAOs9QD1MNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Tree', 'Person', 'Truck']\n",
        "\n",
        "for label in labels:\n",
        "  os.makedirs(f'/content/data/train/{label}', exist_ok=True)\n",
        "  os.makedirs(f'/content/data/train/{label}', exist_ok=True)\n",
        "\n",
        "  os.makedirs(f'/content/data/val/{label}', exist_ok=True)\n",
        "  os.makedirs(f'/content/data/val/{label}', exist_ok=True)"
      ],
      "metadata": {
        "id": "j282RSwP1rOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/data/obj/train/'\n",
        "DATA_ROOT = '/content/data/'\n",
        "\n",
        "VAL_THRESHOLD = 0.2\n",
        "\n",
        "for category in os.listdir(path):\n",
        "  category_path = path+category\n",
        "\n",
        "  for i in os.listdir(category_path):\n",
        "    if i[-4:] == '.jpg':\n",
        "      file_name = i\n",
        "      image_file = category_path + '/' + i\n",
        "      rand_num = np.random.rand()\n",
        "      target = 'val' if rand_num <= VAL_THRESHOLD else 'train'\n",
        "      os.rename(image_file, f'/content/data/{target}/{category}/{i}')"
      ],
      "metadata": {
        "id": "MGCYhsE41L_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.rename('/content/data/obj', '/content/obj')\n",
        "os.rename('/content/data/obj.names', '/content/obj.names')\n",
        "os.rename('/content/data/train.txt', '/content/train.txt')"
      ],
      "metadata": {
        "id": "08lDsq1n8Y2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyxsPf7JE8iO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c054fb0-7b16-429f-d31d-47c4c6d67b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.148 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/content/data, epochs=20, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train5\n",
            "Overriding model.yaml nc=1000 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
            "YOLOv8n-cls summary: 99 layers, 1442131 parameters, 1442131 gradients\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train5', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mRandomResizedCrop(p=1.0, height=224, width=224, scale=(0.5, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1), HorizontalFlip(p=0.5), ColorJitter(p=0.5, brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.30000000000000004, 1.7], hue=[-0.015, 0.015]), Normalize(p=1.0, mean=(0.0, 0.0, 0.0), std=(1.0, 1.0, 1.0), max_pixel_value=255.0), ToTensorV2(always_apply=True, p=1.0, transpose_mask=False)\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/train5\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       1/20         0G     0.2753         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:17<00:00,  1.15s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.12it/s]\n",
            "                   all        0.4          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       2/20         0G     0.2144         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.03s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.14it/s]\n",
            "                   all      0.633          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       3/20         0G     0.1612         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.02s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s]\n",
            "                   all      0.683          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       4/20         0G      0.114         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.06it/s]\n",
            "                   all      0.733          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       5/20         0G    0.08431         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.04s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.34s/it]\n",
            "                   all      0.767          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       6/20         0G    0.07614         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.02s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.11it/s]\n",
            "                   all        0.8          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       7/20         0G    0.06811         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.02s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s]\n",
            "                   all      0.767          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       8/20         0G    0.04843         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.02s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.19it/s]\n",
            "                   all      0.783          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       9/20         0G    0.02943         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.17it/s]\n",
            "                   all      0.783          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      10/20         0G    0.02944         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.05it/s]\n",
            "                   all      0.783          1\n",
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      11/20         0G    0.02771         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.05s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.30s/it]\n",
            "                   all       0.75          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      12/20         0G    0.02305         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.03s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.18it/s]\n",
            "                   all      0.767          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      13/20         0G    0.01671         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.19it/s]\n",
            "                   all      0.767          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      14/20         0G    0.02172         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s]\n",
            "                   all       0.75          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      15/20         0G    0.02428         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.19it/s]\n",
            "                   all      0.783          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      16/20         0G    0.03106         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s]\n",
            "                   all       0.75          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      17/20         0G    0.02208         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:02<00:00,  1.33s/it]\n",
            "                   all      0.767          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      18/20         0G    0.01562         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:18<00:00,  1.24s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.19it/s]\n",
            "                   all       0.75          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      19/20         0G    0.01631         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.20it/s]\n",
            "                   all       0.75          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      20/20         0G    0.01831         16        224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:15<00:00,  1.01s/it]\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:01<00:00,  1.04it/s]\n",
            "                   all       0.75          1\n",
            "\n",
            "20 epochs completed in 0.099 hours.\n",
            "Optimizer stripped from runs/classify/train5/weights/last.pt, 3.0MB\n",
            "Optimizer stripped from runs/classify/train5/weights/best.pt, 3.0MB\n",
            "Results saved to \u001b[1mruns/classify/train5\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-cls.pt')\n",
        "\n",
        "results = model.train(data='/content/data', epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!scp -r runs '/content/drive/MyDrive/Computer Vision Projects/Yolo/'\n",
        "!scp -r runs '/content/'"
      ],
      "metadata": {
        "id": "QrMpsXWYZcc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = model.val()\n",
        "metrics.top1   # top1 accuracy"
      ],
      "metadata": {
        "id": "uBW6tEfoZARR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6a24e3-7276-4489-bea7-6cb781402e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ultralytics YOLOv8.0.148 üöÄ Python-3.10.12 torch-2.0.1+cu118 CPU (Intel Xeon 2.20GHz)\n",
            "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.09it/s]\n",
            "                   all        0.8          1\n",
            "Speed: 0.0ms preprocess, 16.0ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/classify/val2\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.800000011920929"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.top5   # top5 accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVrkZgOKRjvh",
        "outputId": "67234882-161d-4f7c-a982-6d9cbebbaffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model('/content/blue-truck-homepage-618x340.jpg')  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8haxuQXRuyo",
        "outputId": "732ff60b-0136-4601-af05-571cf9cadeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/blue-truck-homepage-618x340.jpg: 224x224 Truck 1.00, Person 0.00, Tree 0.00, 30.6ms\n",
            "Speed: 1.8ms preprocess, 30.6ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owNnEPXdRzVV",
        "outputId": "5b33f065-28d5-443d-d086-d540c82ebe41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: None\n",
              " keypoints: None\n",
              " keys: ['probs']\n",
              " masks: None\n",
              " names: {0: 'Person', 1: 'Tree', 2: 'Truck'}\n",
              " orig_img: array([[[213, 172, 140],\n",
              "         [211, 170, 138],\n",
              "         [208, 167, 135],\n",
              "         ...,\n",
              "         [223, 203, 186],\n",
              "         [225, 206, 191],\n",
              "         [228, 209, 194]],\n",
              " \n",
              "        [[213, 172, 140],\n",
              "         [210, 169, 137],\n",
              "         [207, 166, 134],\n",
              "         ...,\n",
              "         [225, 205, 188],\n",
              "         [227, 208, 193],\n",
              "         [229, 210, 195]],\n",
              " \n",
              "        [[211, 170, 138],\n",
              "         [209, 168, 136],\n",
              "         [206, 165, 133],\n",
              "         ...,\n",
              "         [229, 209, 192],\n",
              "         [228, 209, 194],\n",
              "         [231, 212, 197]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[186, 197, 205],\n",
              "         [181, 192, 200],\n",
              "         [179, 190, 198],\n",
              "         ...,\n",
              "         [200, 209, 212],\n",
              "         [198, 207, 210],\n",
              "         [200, 209, 212]],\n",
              " \n",
              "        [[186, 197, 205],\n",
              "         [181, 192, 200],\n",
              "         [180, 191, 199],\n",
              "         ...,\n",
              "         [198, 207, 210],\n",
              "         [196, 205, 208],\n",
              "         [199, 208, 211]],\n",
              " \n",
              "        [[187, 198, 206],\n",
              "         [182, 193, 201],\n",
              "         [180, 191, 199],\n",
              "         ...,\n",
              "         [198, 207, 210],\n",
              "         [201, 210, 213],\n",
              "         [203, 212, 215]]], dtype=uint8)\n",
              " orig_shape: (340, 618)\n",
              " path: '/content/blue-truck-homepage-618x340.jpg'\n",
              " probs: ultralytics.engine.results.Probs object\n",
              " save_dir: None\n",
              " speed: {'preprocess': 1.8031597137451172, 'inference': 30.628204345703125, 'postprocess': 0.09059906005859375}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "res = plt.imread('/content/blue-truck-homepage-618x340.jpg')\n",
        "plt.imshow(res)"
      ],
      "metadata": {
        "id": "LU5b0mtsR3Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AyNe2yV6XtnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zHMmstdiZ4CP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PRhn_kDuWeIV"
      ],
      "mount_file_id": "1UgnJpOsz1gkeMcHt9NzdSkiGXMra3Bg8",
      "authorship_tag": "ABX9TyM7jX/5S1Gsh+bbVsIB3cnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}